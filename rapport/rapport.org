#+INCLUDE: "header.org"

* L'équipe /STORM/ Inria Sud-ouest
:PROPERTIES:
:UNNUMBERED: t
:END:
\newpage
* Introduction
** Le domaine du calcul haute performance

   Dans le domaine du calcul haute performance, il est d'usage d'utiliser
   plusieurs unités de calculs en parallèle afin de traiter des problèmes de
   plus en plus rapidement. Ces unités de calculs peuvent être des CPUs
   (processeur) ou des GPUs (carte graphique). Dans la suite de ce rapport, nous
   appellerons /ouvrier/ une unité de calcul (CPU ou GPU).

   Afin d'utiliser au mieux ce matériel, il convient d'utiliser des paradigmes
   de programmation adapté. Une méthode qui a déjà était le sujet de nombreuses
   recherches est la programmation en tâches. Une tâche représente un
   sous-ensemble du problème à résoudre. Programmer avec des tâches consiste
   donc à construire plusieurs sous-ensemble du problème et définir comment
   chaque sous-ensemble est lié aux autres sous-ensembles à l'aide de
   dépendances de tâches. Nous obtenons alors un arbre de dépendances de tâches.
   Enfin nous les donnons à résoudre à des ouvriers différents, dans un ordre
   qui dépend de l'arbre de tâches construit. Un exemple de graphe de
   dépendances de tâches est illustré figure [[fig:task-deps]].

#+NAME: fig:task-deps
#+CAPTION: Graphe de dépendances de tâches.
#+ATTR_LATEX: :width 0.4\linewidth
[[file:img/task-deps.pdf]]

** Qu'est-ce qu'une application stencil ?
   Il s'agit d'une classe d'algorithmes beaucoup utilisé en simulation (telle
   que simulation de gaz ou de propagation de chaleur). Un tel algorithme
   permet généralement de discrétiser des phénomènes physiques locaux sur des
   grilles régulières.

   La dimension temporelle est exprimée par des itérations. Une itération
   consiste à appliquer une petite fonction sur chaque cellule d'une grille.
   Cette fonction ayant la particularité de mettre à jour le contenu d'une
   cellule en fonction de son voisinage (illustrée figure [[fig:3D_stencil]]).

   Pour résoudre un problème stencil à l'aide de tâches, nous pouvons regrouper
   plusieurs mises à jour de cellules voisines en une tâche. Il faut alors
   regrouper suffisamment de mises à jour pour que cette tâche représente un
   calcul conséquent.

#+NAME: fig:3D_stencil
#+CAPTION: Stencil 6-points 3D - La mise à jour d'un élément se fait ici à partir
#+CAPTION: des 6 éléments voisins cite:6points-stencil.
#+ATTR_LATEX: :width 0.2\linewidth
[[file:img/3D_stencil.png]]
** Sujet d'étude et plan
   Un support d'exécution est une couche logicielle permettant de traiter des
   problèmes de calcul haute performance de manière générique. Au cours du stage
   nous avons cherché à savoir si /StarPU/, le support d'exécution développé
   dans l'équipe /STORM/, peut aussi traiter des applications stencil
   efficacement.

   Dans la section [[#sec:contexte]] nous discuterons du contexte du stage. Nous
   reviendrons en détail sur les particularités des applications stencil, sur la
   programmation en tâches ainsi que les supports d'exécutions. Nous terminerons
   sur l'État de l'art dans le domaine.

   Dans la section [[#sec:contrib]] nous détaillerons les travaux principaux
   réalisés durant le stage :
   - outil simple pour visualiser les décisions prises par /StarPU/ pour des
     applications stencil,
   - évaluation et comparaison des algorithmes déjà présent dans /StarPU/ pour
     des applications stencil.

   Enfin, dans la section [[#sec:concl]] nous résumerons les points importants du
   stage et nous discuterons des perspectives qui en résultent.
* Contexte
:PROPERTIES:
:CUSTOM_ID: sec:contexte
:END:
   Dans cette section, nous présentons le contexte du stage. Nous revenons plus
   en détails sur la programmation parallèle en tâches, sur les supports
   d'exécution ainsi que sur les particularités des applications stencil.
** Ordonnancer un ensemble de tâches
   Ordonnancer une tâche signifie demander à un ouvrier (une unité de calcul)
   d'exécuter cette tâche. L'objectif étant de minimiser le temps de calcul
   global de toutes les tâches, une question récurrente lorsqu'on programme des
   tâches est de savoir à qui demande-t-on de calculer une tâches parmi tous les
   ouvriers disponibles. Lorsque l'on ne souhaite utiliser que des CPUs, une
   solution consiste à laisser l'ordonnancement des tâches au système
   d'exploitation. Cette solution perd de son sens lorsque qu'on y ajoute un ou
   plusieurs GPUs. De plus, les politiques d'ordonnancement du système
   d'exploitation ne sont jamais adaptées à l'application.

   Une autre solution consiste à laisser l'utilisateur assigner, une à une, les
   tâches à un ouvrier. Enfin, et c'est le sujet de ce stage, nous pouvons
   laisser l'ordonnancement à des supports d'exécution ou /runtime/ qui vont
   décider pour chaque tâche sur quel ouvrier il convient de la calculer.

   L'objectif du stage consiste à étudier l'ordonnancement d'application de type
   stencils dans un support d'exécution. Nous étudierons en particulier
   l'ordonnancement de tâches dans le support d'exécution /StarPU/, développé
   dans l'équipe /STORM/ Inria Sud-ouest. Les application de type stencils ayant
   des particularités que nous discuterons section [[#sec:com-stencils]], il est
   intéressant d'évaluer si les outils déjà disponibles dans le support
   d'exécution /StarPU/ permettant de traiter de telles applications ou dans le
   cas contraire, d'identifier quels seraient les ajouts nécessaires.
** Architecture hétérogène
   Les machines de calculs sont souvent composées de dizaines de CPUs (/Central
   Processing Unit/) et un, deux voir trois cartes graphiques. On parle alors
   d'architecture hétérogène. Les GPUs (/Graphics Processing Unit/) sont les
   ouvriers des carte graphique. Ils sont généralement bien plus rapide
   que des CPUs pour certaines tâches comme le graphisme. Ils sont aussi
   beaucoup utilisés en calcul haute performance pour faire du calcul
   généraliste.

   Comme illustré figure [[fig:memarch]], chaque carte graphique dispose de sa
   propre mémoire. Celle-ci est cependant plus limitée en volume que la mémoire
   principale, soit quelques gigaoctets pour une carte graphique contre
   plusieurs dizaines de gigaoctet pour la mémoire principale. De plus, les
   ouvriers d'une carte graphique ne peuvent pas directement avoir accès à la
   mémoire principale. Lorsque l'on souhaite accéder à une donnée, il faut la
   charger depuis la mémoire principale vers la mémoire de la carte graphique.
   La latence étant plus élevée qu'un accès par un CPU.

#+NAME: fig:memarch
#+CAPTION: Topologie mémoire d'une machine avec deux cartes graphiques.
#+ATTR_LATEX: :width 0.5\linewidth
[[file:img/memarch.png]]

   Cette latence étant un facteur temporel limitant important, il convient de
   réguler au mieux les transferts vers les mémoires des GPUs. Pour cela, nous
   pouvons essayer de :
   - limiter l'occupation du bus mémoire en réduisant les transferts au strict
     minimum
   - limiter le temps passé à attendre qu'une donnée arrive en mémoire en
   faisant parallèlement des transferts et des calculs. On parle alors de
   recouvrement des transferts mémoires.

** Support d'exécution

    Un support d'exécution est un composant qui vient se placer entre le système
    d'exploitation et l'application comme illustré figure [[fig:runtime]]. Son rôle
    est d'ordonnancer finement les processus parmi les différents ouvriers. Pour
    ce faire, il doit demander au système d'exploitation de laisser le support
    d'exécution se charger de l'ordonnancement des processus. Il peut aussi le
    rôle d'interface avec le protocole de communication MPI et les accélérateurs
    GPU.

#+NAME: fig:runtime
#+CAPTION: Hiérarchie logicielle et support d'exécution.
#+ATTR_LATEX: :width 0.4\linewidth
[[file:img/runtime.pdf]]

    L'utilisateur doit construire un ensemble de tâches pour résoudre un
    problème, et soumettre toutes ces tâches au support d'exécution. Il peut
    ainsi décider de la répartition des tâches de calcul sur les ouvriers à
    disposition. Pour prendre ces décision, il utilise des politiques
    d'ordonnancement ou ordonnanceurs. Nous détaillons quelques exemples section
    [[#sec:detail-sched]].
** Applications stencils
   Pour notre étude, nous utiliserons comme stencil un prototype jouet simple
   afin de faciliter l'analyse des expériences.
*** Schéma de calcul particulier des stencils
    :PROPERTIES:
    :CUSTOM_ID: sec:com-stencils
    :END:
    Les nombreux accès aux cellules voisines lors d'une mise à jour peuvent
    avoir comme principale conséquence un ratio accès mémoire par mise à jour de
    cellule très élevé. Le facteur temporel limitant n'est alors plus le temps
    de calcul mais le temps d'accès mémoire des cellules voisines. De plus, il
    devient alors difficile de recouvrir totalement les temps de transferts
    entre les différents noeuds mémoires par du calcul. Il faut alors faire de
    la réutilisation des données.

# grille avec arrow pour representer les dept
# - decoupage par blocs / taches, schema dep taches precedentes

*** Économiser de la bande passante
:PROPERTIES:
:CUSTOM_ID: sec:stencil-bandwidth
:END:

    Nous nous intéresserons surtout aux problèmes de taille supérieur à la
    mémoire disponible. Ainsi, il ne sera pas possible de stocker l'intégralité
    des données du problème étudié en mémoire GPU, il faudra donc évincer
    régulièrement des données de la mémoire GPU et faire régulièrement des
    transferts depuis la mémoire principale, ce qui a un coût.

    Pour limiter le volume de données transférées, il est nécessaire de
    réutiliser les données déjà présentes en mémoire plutôt que d'en transférer
    de nouvelles. Pour cela, nous pouvons travailler sur la *localité en espace*
    des données en se basant sur l'affirmation suivante : si un emplacement
    mémoire est référencé, il est très probable que les emplacements mémoires
    voisins seront aussi référencés dans un futur proche. Cette affirmation se
    vérifie pour les stencils lors de la mise à jour d'une cellule.

    De plus, du à la nature algorithmique itérative d'un stencil, chaque
    emplacement mémoire est accédé à chaque nouvelle itération sur le stencil.
    Nous aimerions alors travailler sur la *localité temporelle* des données.
    Ainsi, plutôt que de mettre à jour tous les éléments les uns à la suite des
    autres, nous pouvons faire évoluer un petit morceau du domaine. Cela en
    traitant plusieurs itérations de manières successives, comme illustrée
    figure [[fig:local-iter]].

#+NAME: fig:local-iter
#+CAPTION: Exemple d'évolution d'un morceau de domaine pour un stencil 1D.
#+CAPTION: Les chiffres représentent le numéro d'itération. On progresse en
#+CAPTION: diagonale sur un petit morceau du domaine, plutôt que de traiter
#+CAPTION: une itération complète d'un seul coup.
#+ATTR_LATEX: :width 0.5\linewidth
[[file:img/local-iter.pdf]]

** Répartition de charge

   Pour certain type d'application stencil comme la prévision météo, il est
   courant d'utiliser des heuristiques plus ou moins précises (et donc
   coûteuses) selon le domaine. Par exemple, on utilisera une heuristique plus
   approximative pour prévoir le temps qu'il fera sur une région ensoleillée que
   sur une région nuageuse.

   Dans la section [[#sec:load-balance]] nous évaluerons les performances de
   certaines méthodes face à une répartition de charge déséquilibrée. Nous
   regarderons en particulier une répartition de charge statique (où le
   déséquilibre est fixée au départ) et dynamique (où le déséquilibre évolue au
   cours du temps, comme cela peut-être le cas pour la prévision météo).

** État de l'art
*** Les contraintes des applications stencils
    Dans le domaine du calcul haute performance, le paradigme de programmation
    parallèle en tâches est très utilisé. Cependant, pour des machines ayant une
    architecture hétérogène, il peut devenir très complexe de trouver la
    meilleur répartition des tâches sur les différents ouvriers. Pour
    pallier à ce problème, les supports d'exécution sont une solution. Ils
    essayent alors de prendre les décisions d'ordonnancement appropriées.

    La localité des données étant un facteur temporel réducteur important pour
    les applications stencils, il est intéressant d'étudier quelles
    peuvent être les décisions prises par le support d'exécution /StarPU/,
    développé par l'équipe /STORM/, et quelles améliorations nous pouvons
    envisager.

*** Solutions existantes au problème
    Le domaine des stencils reste un problème très étudié en calcul haute
    performance. Cependant, la répartition des calculs est en général fait à la
    main. Des travaux ont aussi portés sur des algorithmes caches oblivieux ou
    /oblivious/ adaptés aux stencils cite:frigo-co-stencil. Ceux-ci tentent de
    profiter du cache sans connaître la taille du cache. Pour cela, on favorise
    la réutilisation des données. Cela nécessite aussi une charge de travail
    supplémentaire pour l'utilisateur.

    De précédents travaux dans l'équipe /STORM/ portant sur des applications
    d'algèbre linéaire dense, creuse et compressée ont montré que le support
    d'exécution /StarPU/ pouvait apporter des performances similaires qu'un code
    taillé sur mesure. En revanche, peu de travaux ont été réalisés dans
    l'équipe concernant les stencils. Nous voulons savoir si les
    supports d'exécution peuvent traiter ce problème de manière *générique*.

    Pour s'assurer que le support d'exécution prend des décisions
    d'ordonnancement favorisant la localité, nous avons besoins d'outils de
    visualisation adaptés au problème. Ces outils doivent nous permettre
    d'évaluer les ordonnanceurs et donc éventuellement de proposer des
    améliorations.

* Contribution du stage
:PROPERTIES:
:CUSTOM_ID: sec:contrib
:END:
** Résumé de la contribution
   Nous avons étudié le comportement du support d'exécution /StarPU/ pour des
   applications stencils. Pour les évaluer, nous les comparons avec une méthode
   très spécifique aux stencils (et donc non générique) qui nécessite des
   changements dans l'application : il s'agit de l'algorithme de soumission de
   tâches cache oblivieux.

   Pour comprendre les performances obtenues avec /StarPU/, nous avons besoin
   d'observer la localité en espace et en temps des données. Ceci permettant de
   réduire le volume des transferts mémoires. Nous avons écrit des outils de
   visualisation adaptés détaillés section [[#sec:outil-visu]].

   Enfin, nous avons assemblé un ordonnanceur simple adapté aux applications de
   type stencil détaillé section [[#sec:mod-heft]].
** Ordonnanceurs : recouvrir les transferts mémoires et localité des données
   :PROPERTIES:
   :CUSTOM_ID: sec:detail-sched
   :END:
   Nous allons décrire dans cette section quelques ordonnanceurs du support
   d'exécution /StarPU/. C'est généralement l'application qui décide du type
   ordonnanceurs à utiliser.
*** /Eager/ (=eager= et =prio=)
    L'ordonnanceur =eager= utilise une seule liste centralisée pour tous les
    ouvriers. Il distribue les tâches aux ouvriers suivant un ordonnancement
    tourniquet ou /round-robin/. Il existe une variante de =eager= appelée
    =prio=. Celle-ci prend en compte les priorités que l'application peut
    assigner aux tâches. Elle ordonnance les tâches à priorité élevée en
    premier.

    Cet ordonnanceur ne travail pas du tout sur la localité des données.
    Cependant, en utilisant cet ordonnanceur, l'application peut feindre de la
    localité des données. Pour cela nous attribuons une priorité croissante avec
    le numéro d'itération. Nous espérons ainsi que l'ordonnanceur ait tendance à
    faire évoluer des groupes de cellules proches comme illustré sur la figure
    [[fig:local-iter]]. Nous vérifions cela section [[#sec:prio-locality]].
*** /Deque Model Data Aware/ (=dmda= et =dmdar=)
  Chaque ouvrier dispose de sa propre file de tâches. Lorsque l'ordonnanceur
  =dmda= souhaite assigner une tâche, il calcule pour chaque ouvrier une date de
  terminaison de la tâche. Cette date dépend du nombre de tâches pas encore
  terminées présentes dans la file, de la durée de la tâche et de la vitesse de
  calcul de l'ouvrier. =dmda= prend aussi en compte la durée nécessaire au
  transfert des données de la tâche comme illustrée figure \ref{fig:dmda}. Cela
  réduit les transferts entre mémoire GPU et mémoire principale.

  =dmdar= est une variante de =dmda=. Chaque ouvrier va sélectionner en premier,
  dans sa file, les tâches ayant le plus de données déjà disponibles dans sa
  mémoire. Cela permet de maximiser le recouvrement des transferts par du
  calcul.
#+BEGIN_LATEX
\begin{figure}
\centering
\hspace*{\fill}
\subfloat[Situation de départ.]
  {\includegraphics[width=0.3\linewidth]{img/sched_dmda_1.pdf}}
\hspace*{\fill}
\subfloat[On calcule le temps de calcul de la tâche en vert.]
  {\includegraphics[width=0.3\linewidth]{img/sched_dmda_2.pdf}}
\hspace*{\fill}
\subfloat[Recherche du temps de terminaison minimum.]
  {\includegraphics[width=0.3\linewidth]{img/sched_dmda_3.pdf}}
\hspace*{\fill}
\newline
\hspace*{\fill}
\subfloat[Le GPU 2 semble être le meilleur candidat.]
  {\includegraphics[width=0.3\linewidth]{img/sched_dmda_4.pdf}}
\hspace*{\fill}
\subfloat[Cette fois-ci, on prend en compte les temps de transferts en rouge.
          Le meilleur candidat est donc le CPU 3.]
  {\includegraphics[width=0.3\linewidth]{img/sched_dmda_5.pdf}}
\hspace*{\fill}
\caption{\label{fig:dmda}
Ordonnancement d'une tâche pour l'ordonnanceur \texttt{dmda}.}
\end{figure}
#+END_LATEX
*** /Locality Work Stealing/ (=lws=)
    L'ordonnanceur =lws= distribue les tâches aux différents ouvriers en
    fonction de la charge (durée de la tâche) et de la localité des données.
    Un ouvrier pourra faire du vol de travail s'il se retrouve inactif. Il pourra
    alors aller prendre une tâche d'un ouvrier voisin déjà bien chargé.
    L'ordonnanceur =lws= est illustré figure [[fig:sched_ws]].

    # plus de transferts en les noeuds mémoire que cache oblivious
#+NAME: fig:sched_ws
#+CAPTION: Ordonnanceur =lws= (/Work Stealing/).
#+ATTR_LATEX: :width 0.5\linewidth
[[file:img/sched_ws.png]]

# *** Heteroprio
# - heteroprio (https://hal.inria.fr/hal-00807368) qui est centralisé comme
# - eager, mais regarde combien les tâches sont accélérées pour décider # -
# - entre CPU et GPU
*** /Modular-heft/
    :PROPERTIES:
    :CUSTOM_ID: sec:mod-heft
    :END:

    Cet ordonnanceur est illustré figure [[fig:sched_mod_heft]]. Sa particuliarité
    est qu'il s'agit d'un ordonnanceur modulaire, construit par assemblage de
    composants. Ainsi, il est aisé de construire un nouveau ordonnanceur en
    ajoutant ou modifiant un composant.

    Le principe est le suivant. Chaque ouvrier dispose de sa file de tâche. Tant
    qu'il reste des tâches dans sa file, on récupère une tâche prête dans la
    liste et on l'exécute. Une tâche prête est une tâche dont les données se
    trouvent déjà en mémoire pour un noeud donné. Le recouvrement des transferts
    mémoires est donc crucial ici.

    Lorsque la liste est vide, on va aller notifier le composant racine.
    Celui-ci va alors essayer de pousser des tâches dont les données se
    trouvent déjà dans la mémoire de cet ouvrier.

    Le composant /mct/ (/Manufacturing Critical Time/) récupère les tâches
    poussées par la racine, et va estimer une date de terminaison de la tâche
    pour chacun de ses composants fils (les composants ouvriers). Cette date
    dépend de la durée de la tâche, de la vitesse de l'ouvrier et de la durée
    des éventuels transferts. Il sélectionne la date la plus proche dans le
    future et envoie la tâche à l'ouvrier correspondant.
#+NAME: fig:sched_mod_heft
#+CAPTION: Ordonnanceur =modular-heft=.
#+ATTR_LATEX: :width 0.7\linewidth
[[file:img/sched_mod_heft.png]]
** Méthode de référence : Algorithme cache oblivieux de soumission de tâches
    Pour évaluer les ordonnanceurs du support d'exécution /StarPU/, nous avons
    besoin d'une méthode de référence. Pour cela, nous utilisons le résultat de
    précédentes recherches portant sur un algorithme cache oblivieux adaptés au
    stencil cite:frigo-co-stencil. Nous avons implémenté cet algorithme tel
    qu'il y est décrit.

    Cet algorithme décrit un ordre dans lequel faire les mises à jour des
    cellules qui favorise la réutilisation des données. Nous n'utilisons pas
    d'ordonnanceurs et laissons l'utilisateur décider quelle tâche sera exécutée
    sur quel ouvrier et dans quel ordre. Nous soumettons les tâches dans l'ordre
    dicté par l'algorithme cache oblivieux afin de limiter le volume de données
    transférées. Il devrait s'agir d'une méthode proche de l'idéale lorsque le
    problème étudié est trop grand pour rentrer en mémoire GPU.

    L'algorithme ayant été pensé pour une exécution en séquentiel, il a fallu
    l'adapter pour une exécution en parallèle. Pour cela, nous découpons le
    problème en autant de sous-domaines que nous disposons de cartes graphiques.
    Nous appliquons un l'algorithme cache oblivieux de manière locale pour
    chaque sous-domaine.

    *???* est-ce que j'explique ici l'ajout de sémaphores pour respecter les
    dépendances ?

** Outils de visualisation
   :PROPERTIES:
   :CUSTOM_ID: sec:outil-visu
   :END:

   Maintenant que nous avons une méthode de référence, il faut pouvoir
   comprendre ce que les ordonnanceurs font de bien ou mal. L'outil /StarPU/
   dispose déjà d'outils d'analyse de traces qui permettent d'observer si un
   ouvrier est actif ainsi que les transferts mémoires, et cela pour chaque
   instant de l'exécution. Cela ne nous suffit pas, en effet, nous voulons
   observer la localité des données.
*** Diagramme d'exécution : domaine en fonction du temps
    Un exemple d'un tel diagramme est donné figure \ref{fig:example-xpm}. Sur ce
    diagramme nous pouvons observer quel ouvrier (couleur rouge, bleu, et vert)
    a travaillé sur quel morceau du domaine (axe des ordonnées) et à quel
    instant dans l'exécution (axe des abscisses). Nous pouvons aussi voir les
    transferts mémoires (couleur cyan, magenta et jaune).
#+BEGIN_LATEX
\begin{figure}
\centering
\subfloat[Exécution avec deux GPUs.]
  {\includegraphics[width=0.9\linewidth]{img/example.png}}
  \newline
\subfloat[Légende.]
  {\includegraphics[width=0.6\linewidth]{img/xpm-legend.png}}
\caption{\label{fig:example-xpm}
Exemple de diagramme d'exécution des tâches : domaine en fonction du temps.}
\end{figure}
#+END_LATEX
*** Diagramme d'exécution : domaine en fonction des itérations
    Un exemple d'un tel diagramme est donné figure \ref{fig:example-iter-xpm}.
    Sur ce diagramme nous pouvons observer quel ouvrier a travaillé sur quel
    morceau du domaine et à quelle itération du stencil. En noir sont aussi
    affichées des courbes isochrones. Elle permettent d'intégrer une dimension
    temporelle dans le diagramme. Tout ce qui se trouve entre deux courbes
    isochrones à la verticale s'est déroulé durant le même laps de temps. Sur
    l'exemple de la figure \ref{fig:example-iter-xpm}, la durée entre deux
    courbes isochrones est de 100ms.
#+BEGIN_LATEX
\begin{figure}
\centering
\hspace*{\fill}
\subfloat[Exécution avec deux GPUs.]
  {\includegraphics[width=0.55\linewidth]{img/example-iter.pdf}}
\hspace*{\fill}
\subfloat[Légende.]
  {\includegraphics[width=0.45\linewidth]{img/xpm-legend-iter.png}}
\hspace*{\fill}
\caption{\label{fig:example-iter-xpm}
Exemple de diagramme d'exécution des tâches : domaine en fonction des itérations.}
\end{figure}
#+END_LATEX

** Évaluation
 - Comportement des ordonnanceurs de StarPU, 3 métriques à considérer
   + temps d'exécution
   + surcoût : temps passé à ordonnancer les tâches
   + volume des transferts GPU/GPU ou CPU/GPU
 - rappel : on s'intéresse surtout aux cas où on a pas assez de mémoire
# Expérimentation : montrer et donc expliquer certaines courbes ou images intéressantes
# Permet d'appuyer la pertinence des travaux présentés

*** Expérimentation simulées à l'aide de /SimGrid/
    /SimGrid/ est un composant logiciel qui permet de simuler des expériences
    dans le domaine du calcul haute performance ou dans le /cloud computing/ ou
    informatique en nuage. Tous les composants d'une expérience peuvent être
    simulés : architecture de la machine ou du réseau de machines, temps de
    calculs, temps de transferts mémoires...

    Cela permet de tester rapidement des expériences même extrême (taille du
    problème très grand par exemple). De plus, la simulation apporte un aspect
    reproductible et déterministe, ce qui n'est pas forcément le cas pour
    certaines heuristiques.

    La validation de ces expériences sur de vraies machines, en utilisant un
    stencil moins factice que celui utilisé, ne sera pas faite durant le stage.
*** Le programme de test utilisé : un stencil 1D
    + stencil jouet faux stencil fait pas de calcul, attend un temps predettermine
    + on simule des blocs en disant ce truc la fait 3mo
    + on arrange la taille des blocs pour que duree transfert = 2 x temps de calcul
    + y'a aussi des cas ou on a 6 voir 20 fois pas assez de memoire
    + montrer un exemple simple de stencil
    + du pseudo code pour dmdar avec soumission alterné
    + ainsi que pour cache oblivious parallèle mais sans entrer dans les détails
    de cache oblivious
# indique explicitement que tu as implémenté l'algo cache oblivious tel que
# décrit dans l'article

*** courbes dmdas lws cache oblivious modular heft
*** performances courbes dmdas / cache oblivious (avec description de ce qu'on y voit)

# pour chaque section suivantes choisir la bonne visualisation pour illustrer le
# propos
*** avec et sans limite mémoire
# sans limite mémoire, cache oblivious est idéal a priori: on paie seulement le
# coût des tous premiers chargements, après le gpu est occupé à 100% du temps.
*** prefetch et sans prefetch *???*
    + on confirme que cache oblivious s'en sort bien même quand peu de mémoire
    + dmdar très proche de notre idéal (peut-être trop pour les cas sans limite
      mémoire *???* est-ce que cache
    oblivious est vraiment idéal ?)
    # répartition de charge: je dirais d'en faire une section à part, pour
    # garder dans un premier temps un cas simple, pour montrer "on fait pas loin
    # d'aussi bien que cache oblivious", et puis ensuite "ah ben en fait c'est
    # beaucoup mieux"
*** répartition de charge inégale : cache oblivious à la traine
:PROPERTIES:
:CUSTOM_ID: sec:load-balance
:END:

      * et si on prédécoupe à la main, est-ce intéressant à montrer *???*
      # c'est intéressant de montrer qu'en prédécoupant à la main on retrouve un
      # équilibre de charge, oui, mais là on enfonce le clou en utilisant une
      # répartition de charge dynamique

    + répartition de charge dynamique (en fonction du temps) : avoir recours à
      des partitionneurs, c'est pas du tout trivial (mettre références)
    + ref AMR
#+NAME: fig:load_gpu2_limit0
#+CAPTION: Influence de répartitions de charge inégales sur l'ordonnanceur =dmdar=
#+CAPTION: et via une soumission des tâches cache oblivieux - deux GPU, pas de
#+CAPTION: limite mémoire
#+ATTR_LATEX: :width 0.8\linewidth
[[file:exp/load_gpu2_limit0.pdf]]

*** cache oblivious mirroir ou pas mirroir
*** prio locality
:PROPERTIES:
:CUSTOM_ID: sec:prio-locality
:END:

*** que faut-il en retenir

* Conclusion
:PROPERTIES:
:CUSTOM_ID: sec:concl
:END:
** Court résumé des points importants

- Problème initial
  + on s'est intéressé à l'ordonnacement d'application stencil dans le Runtime StarPU
  + ratio transfert / temps de calcul des stencils, dur de tout recouvrir par du calcul
  + pour des cas ne tenant pas en mémoire
- Contribution
  + outil de visualisation pour comprendre les choix effectués lors de l'ordonnancement
  + trouver un élément de comparaison pour évaluer les éléments déjà présents (dmdar)
- Validation
  + quelques expériences pour vérifier
  + que faut-il en retenir

** Perspectives

# (faute de temps) : autre solution technique figurant sur l'arbre des solutions, cul-de-sac
- Court terme
  + un LRU optimal pour du stencil et pour pour plusieurs GPU
  + validation avec stencil 2D sur de vraies machines pour l'evaluation

# quelles sont les voies d'exploration non envisagées au départ ?
- Long terme
  - projet Hibox avec airbus pour algebre lineaire compressée
    + out of core : CPU <-> disk
    + pas la même échelle au niveau de la latence
  - visualisation de stencil en 2D, 3D ou ND
    + faire N figures ? faire un film ?
    + travaux de questionnement de la visualisation pour l'equipe grenoble Polaris
      (vinicius ref (vite))
  - charge dynamique : repartionnement
  - stencil MPI
    + redistribution des données
    + pas de petit transfert cell par cell (enorme latence)
  - detecter convergence stencil non pas au niveau applicatif (barriere) dans
    dans starpu

#+LATEX: \clearpage
#+LATEX: \printbibliography

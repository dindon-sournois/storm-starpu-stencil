#+INCLUDE: "header.org"

* L'équipe /STORM/ Inria Sud-ouest
\newpage

* Introduction
** Le domaine du calcul haute performance
   Dans le domaine du calcul haute performance, il est d'usage d'utiliser
   plusieurs unités de calculs en parallèle afin de traiter des problèmes de
   plus en plus rapidement. Ces unités de calculs peuvent être des CPUs
   (processeur) ou des GPUs (carte graphique).

   Pour traiter des données de plus en plus conséquente, nous pouvons utiliser
   des machines reliées en réseau et communicant avec un protocole adapté (e.g.
   /Message Passing Interface/ ou MPI).

   Il est courant de mélanger toutes ces technologies lors d'une même exécution.
   Certains serveur de calcul disposent alors de plusieurs machines
   communicantes. Chaque machine ayant une architecture dit hétérogène, pouvant
   contenir à la fois des CPUs et des GPUs. Dans ce stage, nous ne nous
   intéresserons pas à la programmation distribuée sur plusieurs machines.

   Afin d'utiliser au mieux ce matériel, il convient d'utiliser des paradigmes
   de programmation adapté. Une méthode qui a déjà était le sujet de nombreuses
   recherches est la programmation en tâches. Une tâche représente un
   sous-ensemble du problème à résoudre. Programmer avec des tâches consiste
   donc à construire plusieurs sous-ensemble du problème et définir comment chaque
   sous-ensemble est lié aux autres sous-ensembles à l'aide de dépendances de
   tâches. Nous obtenons alors un arbre de dépendances de tâches. Enfin nous
   les donnons à résoudre à des unités de calcul différentes dans un ordre qui
   dépend de l'arbre de tâches construit. Un exemple d'arbre de dépendances de
   tâches est illustré figure [[fig:task-deps]].

#+NAME: fig:task-deps
#+CAPTION: Arbre de dépendances de tâches.
#+ATTR_LATEX: :width 0.4\linewidth
[[file:img/task-deps.pdf]]
** Ordonnancer un ensemble de tâches
   L'objectif étant de minimiser le temps de calcul global de toutes les tâches,
   une question récurrente lorsqu'on programme des tâches est de savoir à qui
   demande-t-on de calculer une tâches parmi toutes les unités de calcul
   disponibles. Lorsque l'on souhaite n'utiliser que des CPUs, une solution
   consiste à laisser l'ordonnancement des tâches au système d'exploitation.
   Cette solution perd de son sens lorsque qu'on y ajoute un ou plusieurs GPUs.
   De plus, le système d'exploitation n'a pas conscience des autres machines
   reliées au réseau.

   Une autre solution consiste à laisser l'utilisateur assigner, une à une, les
   tâches à une unité de calcul. Enfin, et c'est le sujet de ce stage, nous
   pouvons laisser l'ordonnancement à des supports d'exécution ou /runtime/ qui
   vont décider pour chaque tâche sur quelle unité ou quelle machine il convient
   de la calculer.

   L'objectif du stage consiste à étudier l'ordonnancement d'application de type
   stencils (simulation de gaz, de propagation de chaleur, ...) dans un support
   d'exécution. Nous étudierons en particulier l'ordonnancement de tâches dans
   le support d'exécution /StarPU/, développé dans l'équipe /STORM/ Inria
   Sud-ouest. Les application de type stencils ayant des particularités que nous
   discuterons section [[#sec:com-stencils]], il est intéressant d'évaluer les
   outils déjà disponibles dans le support d'exécution /StarPU/ permettant de
   traiter de telles applications ou dans le cas contraire, d'identifier quels
   seraient les ajouts nécessaires.

* Contexte
** Architecture hétérogène
   Il est courant de disposer d'une architecture hétérogène sur nos machines
   pouvant comprendre des dizaines de CPUs et un, deux voir trois cartes
   graphiques. Les GPUs sont généralement bien plus rapide que des CPUs pour
   certaines tâches. Comme illustré figure [[fig:memarch]] chaque carte graphique
   dispose de sa propre mémoire.

   Celle-ci est cependant plus limitée en volume que la mémoire principale, soit
   1 à 4 Go pour une carte graphique contre plusieurs dizaines de Go pour la
   mémoire principale. De plus, les unités de calcul d'une carte graphique ne
   peuvent pas directement avoir accès à la mémoire principale. Lorsque l'on
   souhaite accéder à une donnée, il faut la charger depuis la mémoire
   principale vers la mémoire de la carte graphique. La latence étant plus
   élevée qu'un accès par un CPU.

   Il est donc sage de réduire le volume de données transférées au minimum. Pour
   limiter l'impact de la durée des transferts mémoires, une méthode consiste à
   prévoir, à l'avance, quand une unité de calcul aura besoin d'une donnée en
   mémoire, et de commencer à transférer cette donnée dès que possible. On parle
   alors de recouvrement des transferts mémoires.

#+NAME: fig:memarch
#+CAPTION: Topologie mémoire d'une machine avec deux cartes graphiques.
#+ATTR_LATEX: :width 0.5\linewidth
[[file:img/memarch.png]]

** Support d'exécution

    Un support d'exécution est un composant qui vient se placer entre le système
    d'exploitation et l'utilisateur comme illustré figure [[fig:runtime]]. Son rôle
    est d'ordonnancer finement les processus parmi les différentes unités de
    calcul. Pour ce faire, il doit demander au système d'exploitation de laisser
    le support d'exécution se charger de l'ordonnancement des processus. Il peut
    aussi le rôle d'interface avec le protocole de communication MPI et les
    accélérateurs GPU.

#+NAME: fig:runtime
#+CAPTION: Hiérarchie logicielle et support d'exécution.
#+ATTR_LATEX: :width 0.4\linewidth
[[file:img/runtime.pdf]]

    Il peut ainsi décider de la répartition des tâches de calcul sur les unités
    de calcul à disposition. Pour prendre ces décision, il utilise des
    politiques d'ordonnancement ou ordonnanceurs. Nous détaillons quelques
    exemples section [[#sec:detail-sched]].
** Applications stencils
*** Qu'est-ce qu'une application stencil ?
    Il s'agit d'une classe d'algorithmes beaucoup utilisé en simulation (telle
    que simulation de gaz ou de propagation de chaleur). Un tel algorithme
    permet généralement de discrétiser des phénomènes physiques locaux sur des
    grilles régulières.

    La dimension temporelle est exprimée par des itérations. Une itération
    consiste à appliquer une petite fonction sur chaque cellule d'une grille.
    Cette fonction ayant la particularité de mettre à jour le contenu d'une
    cellule en fonction de son voisinage (illustrée figure [[fig:3D_stencil]]).

# grille avec arrow pour representer les dept
#+NAME: fig:3D_stencil
#+CAPTION: Stencil 6-points 3D - La mise à jour d'un élément se fait ici à partir
#+CAPTION: des 6 éléments voisins cite:6points-stencil.
#+ATTR_LATEX: :width 0.2\linewidth
[[file:img/3D_stencil.png]]

    Pour notre étude, nous utiliserons comme stencil un prototype jouet simple
    afin de faciliter l'analyse des expériences.

*** Schéma de calcul particulier des stencils
    :PROPERTIES:
    :CUSTOM_ID: sec:com-stencils
    :END:
    Les nombreux accès aux cellules voisines lors d'une mise à jour peuvent
    avoir comme principale conséquence un ratio accès mémoire par mise à jour de
    cellule très élevé. Le facteur temporel limitant n'est alors plus le temps
    de calcul mais le temps d'accès mémoire des cellules voisines. De plus, il
    devient alors difficile de recouvrir totalement les temps de transferts
    entre les différents noeuds mémoires par du calcul. Il faut alors faire de
    la réutilisation des données.

 # - decoupage par blocs / taches, schema dep taches precedentes

*** Économiser de la bande passante
    Nous nous intéresserons surtout aux problèmes de taille supérieur à la
    mémoire disponible. Ainsi, il ne sera pas possible de stocker l'intégralité
    des données du problème étudié en mémoire GPU, il faudra donc faire des
    transferts réguliers, ce qui a un coût.

    Pour limiter le volume de données transférées, il est nécessaire de
    réutiliser les données déjà présentes en mémoire plutôt que d'en transférer
    de nouvelles. Pour cela, nous pouvons travailler sur la localité des données
    en se basant sur les deux affirmations suivantes :

    - localité en espace : si un emplacement mémoire est référencé, il est très
      probable que les emplacements mémoires voisins seront aussi référencés
      dans un futur proche;
    - localité en temps : un emplacement mémoire récemment référencé a beaucoup
      de chance d'être référencé à nouveau dans un futur proche.

    Ces affirmations sont d'autant plus vraies pour les stencils du à la nature
    de la mise à jour d'une cellule.
** État de l'art
*** Les contraintes des applications stencils
    Dans le domaine du calcul haute performance, le paradigme de programmation
    parallèle en tâches est très utilisé. Cependant, pour des machines ayant une
    architecture hétérogène, il peut devenir très complexe de trouver la
    meilleur répartition des tâches sur les différentes unités de calcul. Pour
    pallier à ce problème, les supports d'exécution sont une solution. Ils
    essayent alors de prendre les décisions d'ordonnancement appropriées.

    La localité des données étant un facteur temporel réducteur important pour
    les applications stencils, il est intéressant d'étudier quelles
    peuvent être les décisions prises par le support d'exécution /StarPU/ et
    quelles améliorations nous pouvons envisager.

*** Solutions existantes au problème
    Le domaine des stencils reste un problème très étudié en calcul haute
    performance. Cependant, la répartition des calculs est en général fait à la
    main. Des travaux ont aussi portés sur des algorithmes caches oblivieux ou
    /oblivious/ adaptés aux stencils. Ceux-ci tentent de minimiser le nombre de
    défauts de cache (TODO: définir cette notion) sans connaître la taille du
    cache. Pour cela, on maximise la réutilisation des données
    cite:frigo-co-stencil. Cela nécessite aussi une charge de travail
    supplémentaire pour l'utilisateur.

    *???* Parler du projet agora avec les priorités ? C'est peut-être trop technique
    # Peu de travaux sur les stencils dans l'équipe, oui, seulement récemment
    # avec le projet Aghora, où on a utilisé des priorités pour faire de la
    # localité de manière crado.
    # - (On simule de la localité en donnant des tâches avec des priorités
    #   croissantes avec le temps, indexées sur le numéro d'iteration)
    # - chercher stencil GPU out of core, mais souvent fait à la main pas de
    # manière générique

    De précédents travaux dans l'équipe /STORM/ portant sur des applications
    d'algèbre linéaire dense, creuse et compressée ont montré que le support
    d'exécution /StarPU/ pouvait apporter des performances similaires qu'un code
    taillé sur mesure. En revanche, peu de travaux ont été réalisés dans
    l'équipe concernant les stencils. Nous voulons savoir si les
    supports d'exécution peuvent traiter ce problème de manière générique.

    Pour s'assurer que le support d'exécution prend des décisions
    d'ordonnancement favorisant la localité, nous avons besoins d'outils de
    visualisation adaptés au problème. Ces outils doivent nous permettre
    d'évaluer les ordonnanceurs et donc éventuellement de proposer des
    améliorations.

* Contribution du stage
** Résumé de la contribution

 - Comportement des ordonnanceurs de StarPU, 3 métriques à considérer
   + temps d'exécution
   + surcoût : temps passé à ordonnancer les tâches
   + volume des transferts GPU/GPU ou CPU/GPU
 - rappel : on s'intéresse surtout aux cas où on a pas assez de mémoire
 - Pour réduire le volume de communication. : travail sur la localité
 - Pour observer la localité : prototype d'outils de visualisation
 - Utiliser une méthode de référence : cache oblivious

** Méthode de référence
*** Ordonnacement : recouvrir les transferts mémoire et localité dans l'espace
:PROPERTIES:
:CUSTOM_ID: sec:detail-sched
:END:

   - deque model data aware ready (dmdar)
   - figure diagramme de gantt avec plusieurs noeuds et mises en avant des transferts
   - on explique dmdar (/data aware/ et /ready tasks/)
   - c'est un ordonnanceurs parmis d'autres, donner des exemples supplémentaires
     d'ordonnanceurs *???*
     # - eager qui utilise une seule liste centralisée, avec une variante prio qui
     # prend les priorités en compte.

     # - work stealing qui distribue les tâches
     # en fonction de la charge sans se poser de question de localité quand il
     # n'a pas d'information, et qui ordonnance sur la localité s'il en a, et
     # fait du work stealing si un CPU/GPU devient idle - plus de transferts en
     # les noeuds mémoire que cache oblivious

     # - heteroprio (https://hal.inria.fr/hal-00807368) qui est centralisé comme
     # - eager, mais regarde combien les tâches sont accélérées pour décider # -
     # - entre CPU et GPU
   - /data/ et /ready aware/ on fait du recouvrement
   - pas beaucoup de quoi recouvrir pour les stencils, à confirmer section évaluation
*** Algorithme cache oblivious de soumission de tâches
   - cache oblivious sequentiel cite:frigo-co-stencil
   - on bricole une version parallèle
   - on limite au mimimum les /cache misses/ ou plutôt les transferts mémoire
   - méthode idéale même lorsque la mémoire est limité
   - charge statique
*** répartition de charge : peut-être mettre ça dans l'introduction (ETA)

     + répartition de charge dynamique (en fonction du temps) : avoir recours à des partitionneurs, c'est pas du tout trivial (mettre références)
     + ref AMR

** (prototype *???* Outils de visualisation

# ce qu'il faudrait expliquer au début de cette section, c'est que là, comme ça,
# on ne sait pas vraiment ce que dmdar fait de bien ou mal, on a besoin d'outils
# adaptés pour observer ce qui se passe. Les traces vite montre ce qui se passe,
# mais la vue n'est pas adaptée au cas du stencil: elles ne montrent pas la
# localité des données.

   On explique à quoi servent les figures, ce qu'elles représentent, ce qu'elles
permettent de visualiser ici *???* ou bien parti évaluation lors d'une étude de cas

*** Format utilisé
    - on génère une image au format X-Pixmap
    - /parsing/ de traces générées durant l'exécution
*** Diagramme d'exécution du domaine en fonction du temps
    - comment on détermine le domaine de manière automatique
*** Diagramme d'exécution du domaine en fonction des itérations
    - symbolique des isochrones

** Évaluation

# Expérimentation : montrer et donc expliquer certaines courbes ou images intéressantes
# Permet d'appuyer la pertinence des travaux présentés

*** Expérimentation simulées à l'aide de /SimGrid/
    /SimGrid/ est un composant logiciel qui permet de simuler des expériences
    dans le domaine du calcul haute performance ou dans le /cloud computing/ ou
    informatique en nuage. Tout les composants d'une expérience peuvent être
    simulés : architecture de la machine ou du réseau de machines, temps de
    calculs, temps de transferts mémoires...

    Cela permet de tester rapidement des expériences même extrême (taille du
    problème très grand par exemple). De plus, la simulation apporte un aspect
    reproductible et déterministe, ce qui n'est pas forcément le cas pour
    certaines heuristiques.

    La validation de ces expériences pourrait être faite dans le futur sur de
    vraies machines, en utilisant un stencil moins factice que celui utilisé
    durant le stage.
*** Le programme de test utilisé : un stencil 1D
    + stencil jouet faux stencil fait pas de calcul, attend un temps predettermine
    + on simule des blocs en disant ce truc la fait 3mo
    + on arrange la taille des blocs pour que duree transfert = 2 x temps de calcul
    + y'a aussi des cas ou on a 6 voir 20 fois pas assez de memoire
    + montrer un exemple simple de stencil
    + du pseudo code pour dmdar avec soumission alterné
    + ainsi que pour cache oblivious parallèle mais sans entrer dans les détails
    de cache oblivious
# indique explicitement que tu as implémenté l'algo cache oblivious tel que
# décrit dans l'article

*** courbes dmdas lws cache oblivious modular heft
*** performances courbes dmdas / cache oblivious (avec description de ce qu'on y voit)

# pour chaque section suivantes choisir la bonne visualisation pour illustrer le
# propos
*** avec et sans limite mémoire
# sans limite mémoire, cache oblivious est idéal a priori: on paie seulement le
# coût des tous premiers chargements, après le gpu est occupé à 100% du temps.
*** prefetch et sans prefetch *???*
    + on confirme que cache oblivious s'en sort bien même quand peu de mémoire
    + dmdar très proche de notre idéal (peut-être trop pour les cas sans limite
      mémoire *???* est-ce que cache
    oblivious est vraiment idéal ?)
    # répartition de charge: je dirais d'en faire une section à part, pour
    # garder dans un premier temps un cas simple, pour montrer "on fait pas loin
    # d'aussi bien que cache oblivious", et puis ensuite "ah ben en fait c'est
    # beaucoup mieux"
*** répartition de charge inégale : cache oblivious à la traine

      * et si on prédécoupe à la main, est-ce intéressant à montrer *???*
      # c'est intéressant de montrer qu'en prédécoupant à la main on retrouve un
      # équilibre de charge, oui, mais là on enfonce le clou en utilisant une
      # répartition de charge dynamique
#+NAME: fig:load_gpu2_limit0
#+CAPTION: Influence de répartitions de charge inégales sur l'ordonnanceur =dmdar=
#+CAPTION: et via une soumission des tâches cache oblivieux - deux GPU, pas de
#+CAPTION: limite mémoire
#+ATTR_LATEX: :width 0.8\linewidth
[[file:exp/load_gpu2_limit0.pdf]]

*** cache oblivious mirroir ou pas mirroir
*** que faut-il en retenir

* Conclusion
# 1-2 pages
** Court résumé des points importants

- Problème initial
  + on s'est intéressé à l'ordonnacement d'application stencil dans le Runtime StarPU
  + ratio transfert / temps de calcul des stencils, dur de tout recouvrir par du calcul
  + pour des cas ne tenant pas en mémoire
- Contribution
  + outil de visualisation pour comprendre les choix effectués lors de l'ordonnancement
  + trouver un élément de comparaison pour évaluer les éléments déjà présents (dmdar)
- Validation
  + quelques expériences pour vérifier
  + que faut-il en retenir

** Perspectives

# (faute de temps) : autre solution technique figurant sur l'arbre des solutions, cul-de-sac
- Court terme
  + un LRU optimal pour du stencil et pour pour plusieurs GPU
  + validation avec stencil 2D sur de vraies machines pour l'evaluation

# quelles sont les voies d'exploration non envisagées au départ ?
- Long terme
  - projet Hibox avec airbus pour algebre lineaire compressée
    + out of core : CPU <-> disk
    + pas la même échelle au niveau de la latence
  - visualisation de stencil en 2D, 3D ou ND
    + faire N figures ? faire un film ?
    + travaux de questionnement de la visualisation pour l'equipe grenoble Polaris
      (vinicius ref (vite))
  - charge dynamique : repartionnement
  - stencil MPI
    + redistribution des données
    + pas de petit transfert cell par cell (enorme latence)
  - detecter convergence stencil non pas au niveau applicatif (barriere) dans
    dans starpu

#+LATEX: \clearpage
#+LATEX: \printbibliography
